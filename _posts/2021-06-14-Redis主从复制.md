---
layout:     post
title:      Redis主从复制
subtitle:   Redis主从复制及其原理             
date:       2021-06-14
author:     LG
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - Redis
    
---



# 主从模式:
持久化保证了即使redis服务重启也不会丢失数据，因为redis服务重启后会将硬盘上持久化的数据恢复到内存中，但是当redis服务器的硬盘损坏了可能会导致数据丢失，如果通过redis的主从复制机制就可以避免这种单点故障。

主redis中的数据有两个副本（replication）即从redis1和从redis2，即使一台redis服务器宕机其它两台redis服务也可以继续提供服务。
主redis中的数据和从redis上的数据保持实时同步，当主redis写入数据时通过主从复制机制会复制到两个从redis服务上。
只有一个主redis，可以有多个从redis。主从复制不会阻塞master，在同步数据时，master 可以继续处理client 请求。

# 主从复制流程

## 核心原理
slave node启动，仅仅保存master node的信息，包括master node的host和ip，但是复制流程没开始（master host和ip是从哪儿来的，redis.conf里面的slaveof配置的）。
slave node内部有个定时任务，每秒检查是否有新的master node要连接和复制，如果发现，就跟master node建立socket网络连接。
slave node发送ping命令给master node。
口令认证，如果master设置了requirepass，那么salve node必须发送masterauth的口令过去进行认证。
如果salve node是第一次连接master node则执行全量复制，将所有数据发给slave node。开始full resynchronization的时候，master会启动一个后台线程，开始生成一份RDB快照文件，同时还会将从客户端收到的所有写命令缓存在内存中。RDB文件生成完毕之后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中。然后master会将内存中缓存的写命令发送给slave，slave也会同步这些数据；如果这是slave node重新连接master node，那么master node仅仅会复制给slave部分缺少的数据。master如果发现有多个slave node都来重新连接，仅仅会启动一个rdb save操作，用一份数据服务所有slave node。
master node后续持续将写命令，异步复制给slave node。

## 全量复制
master执行bgsave，在本地生成一份rdb快照文件
master node将rdb快照文件发送给salve node，如果rdb复制时间超过60秒（repl-timeout），那么slave node就会认为复制失败，可以适当调节大这个参数
对于千兆网卡的机器，一般每秒传输100MB，6G文件，很可能超过60s
master node在生成rdb时，会将所有新的写命令缓存在内存中，在salve node保存了rdb之后，再将新的写命令复制给salve node
client-output-buffer-limit slave 256MB 64MB 60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败
slave node接收到rdb之后，清空自己的旧数据，然后重新加载rdb到自己的内存中，同时基于旧的数据版本对外提供服务
如果slave node开启了AOF，那么会立即执行BGREWRITEAOF，重写AOF
rdb生成、rdb通过网络拷贝、slave旧数据的清理、slave aof rewrite，很耗费时间。如果复制的数据量在4G~6G之间，那么很可能全量复制时间消耗到1分半到2分钟。

## 增量复制
如果全量复制过程中，master-slave网络连接断掉，那么salve重新连接master时，会触发增量复制
master直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认backlog就是1MB
msater就是根据slave发送的psync中的offset来从backlog中获取数据的

## 异步复制
master每次接收到写命令之后，现在内部写入数据，然后异步发送给slave node
说明：slave不会过期key，只会等待master过期key。如果master过期了一个key，或者通过LRU淘汰了一个key，那么会模拟一条del命令发送给slave。

## 主从复制的断点续传
从redis 2.8开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。

master node会在内存中常见一个backlog，master和slave都会保存一个replica offset还有一个master id，offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制。但是如果没有找到对应的offset，那么就会执行一次resynchronization。

# 数据同步相关的核心机制
指的就是第一次slave连接msater的时候，执行的全量复制，那个过程里面的一些细节的机制。

## offset
master和slave都会维护一个offset。master会在自身不断累加offset，slave也会在自身不断累加offset。slave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset。

这个倒不是说特定就用在全量复制的，主要是master和slave都要知道各自的数据的offset，才能知道互相之间的数据不一致的情况。

## backlog
master node有一个backlog，默认是1MB大小。master node给slave node复制数据时，也会将数据在backlog中同步写一份。backlog主要是用来做全量复制中断时的增量复制的。

## master run id
我们可以通过cli客户端查看master 的 run id

如果根据host+ip定位master node，是不靠谱的，如果master node重启或者数据出现了变化，那么slave node应该根据不同的run id区分。比如如果master里面本来有100w条数据，slave中也是100w条，但此时master通过冷备份恢复到了80w条，这时slave拿着offset等信息来同步数据了。这里就会出现问题了，因为slave这里是要来异步复制的，但master整个数据都不一样了，我们需要的是全量复制。run id不同就做全量复制。如果需要不更改run id重启redis，可以使用redis-cli debug reload命令。



# 哨兵模式：
## 哨兵模式简介
主机 master 宕机
master一旦宕机后，原来master的工作需要新的机器来做。否则就只有读服务，没有写服务了。
步骤如下:
1. 将宕机的master下线；
2. 找一个slave来作为master;
3. 通知所有的slave连接到新的master;
4. 启动新的master和slave;
5. 全量复制 * N + 部分复制 * N;(看配置)

问题:
1. 谁来确认master宕机了，标准是什么；
2. 找一个master来当slave；谁来找，怎么找法；
3. 确认了新的master,原始的master恢复了怎么办；

那么谁来解决这些问题呢？总得有人来解决这些事情。其实哨兵就是盯着这些机器干活的。

那么什么是哨兵？

哨兵是一个分布式系统，用于对主从结构的每台服务器进行监控，当出现故障时，通过投票机制选择新的master并且将所有的slave连接到新的master。哨兵的主要职责就是监控和选择。

哨兵的作用：
1.  监控
不断的检查master和slave是否正常运行；
master存活检测，master和slave状况检测；
2. 通知
当被监控的服务出现问题时，向其它（哨兵间，客户端）发送通知；
3. 自动故障转移；
断开master和slave的链接，选择一个slave作为master，将其他的slave连接到新的master，并且告知客户端新的服务器地址；

注意:

哨兵也是一个redis服务器，只是不提供数据服务；
通常哨兵数量配置为单数；

## 哨兵配置
配置哨兵
1. 配置一拖二的主从结构；
2. 配置三个哨兵（配置相同，端口不同) 查看sentinel.conf
3. 启动哨兵
redis-sentinel sentinel-端口号.conf

port 26379: 哨兵也是一个服务，也有一个对外的端口；

dir /tmp: 目录；

sentinel monitor mymaster 127.0.0.1 6379 2 ： 后面的2表示的是，如果有2个哨兵认为master挂了，那么master就挂了。一般设置为哨兵的一半 + 1；

sentinel parallel -syncs master 1 : 新的master别切换之后，同时有多少个slave被切换到去连接新master，重新做同步，数字越低，花费的时间越多。假设你的redis是1个master，4个slave，然后master宕机了，4个slave中有1个切换成了master，剩下3个slave就要挂到新的master上面去。这个时候，如果parallel-syncs是1，那么3个slave，一个一个地挂接到新的master上面去，1个挂接完，而且从新的master sync完数据之后，再挂接下一个。如果parallel-syncs是3，那么一次性就会把所有slave挂接到新的master上去。这需要依据服务器的配置来进行配置；

sentinel failover-timeout mymaster 180000:  如果180秒还没同步完数据，那么就认为同步超时了。执行故障转移的timeout超时时长。



先启动主机，再启动从机，最后启动哨兵。 


## 哨兵工作原理：
主从切换

哨兵在进行主从切换过程中经历的三个阶段：
1. 监控
2. 通知
3. 故障转移

### 阶段一： 监控阶段
1. 用于同步各个节点的状态信息
   （1）获取各个sentinel的状态（是否在线）发送ping命令
     (2) 获取master的状态
        （1）master 属性。包括 runid 和 role:master
         （2）各个slave的详细信息（包括ip,端口)
     （3）获取所有的slave的状态(根据master中的slave信息）
     
     
   总的来说,sentinel 会向master，slave 以及其他的sentinel获取状态。同时sentinel之间会组建"对应频道",大家一起发布，订阅消息，收消息，
   同步消息等。
   
   
###    阶段二：通知阶段
   维护长期的信息对等的交换。
   
###     阶段三：故障转移

1. sdown和odown转换机制

sdown是主观宕机，就一个哨兵如果自己觉得一个master宕机了，那么就是主观宕机；odown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，那么就是客观宕机。

sdown达成的条件很简单，如果一个哨兵ping一个master，超过了is-master-down-after-milliseconds指定的毫秒数之后，就主观认为master宕机；sdown到odown转换的条件很简单，如果一个哨兵在指定时间内，收到了quorum指定数量的其他哨兵也认为那个master是sdown了，那么就认为是odown了，客观认为master宕机。

   如果出现问题了。
   
   首先是sentinel1 向master发了一次指令。结果master没理。然后slave1会不断的向master发指令。等发到一定的阶段，那么sentinel2就给master标记一个状态S_DOWN。
    
   除了标记 S_DOWN这个状态，这个sentinel1还会在内网中，也就是在sentinel集群中同步信息: master挂了。
   那会不会是sentinel1自己断了，和master连不上了呢。
   这种情况下,master也会被标记为S_DOWN。但是这个指令，sentinel1无法在sentinel中进行传播。
   如果sentinel集群中的机器收到信息说，master挂了，那么好事的人，就会不断的去发送指令进行确认。然后sentinel集群中的各个节点也把他们的结果信息也传播到内网里。
   当所有的sentinel节点都认为master挂了，那么master的状态就会被改为O_DOWN. 实际上半数以上的sentinel节点认为master down了，那么master的状态就被改为O_DOWN了。
   对于S_DOWN的，我们认为是主观下线。对于O_DOWN的，我们认为是客观下线。
   一旦确认master是O_DOWN的，那么我们就开始进入下一个环节了。    
   
   我们可以理解为sentinel集群是一个小团体。如果master已经被认定是客观下线的了，那么就开始进入清理阶段了。那么那个sentinel节点负责去清理呢？所以得选举出一个领头的sentinel。sentinel集群中的每一个sentinel节点都向其它sentinel节点传递这样的一个信息:
 发送:
 sentinel is-master-down-by-addr.....
 挂的ip
 挂的端口
 竞选次数
 自己的runid
 
 每个sentinel作为参选者，同时也作为投票者，每个sentinel都有一票。比如: 如果sentinel1 和 sentinel4 都向 sentinel发送了信息，那么sentinel2会根据信息到达的先后顺序，那个sentinel的信息先到达，那么就投给谁。
 
 那么被选举出来的sentinel就开始从服务器列表中挑选备选的master了。
 sentinel会根据如下的原则挑选master:
 1.  在线的；
 2.  过滤掉响应慢的；
 3. 与原master断开时间久的；
 4. 根据优先原则
   （1）优先级：按照slave优先级进行排序，slave priority（配置）越低，优先级就越高；
     (2) offset 偏移量： 如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高。
     (3)  runid：如果上面两个条件都相同，那么选择一个run id比较小的那个slave。
 发送指令(sentinel)
 1. 向新的master发送 slave of no one;
 2. 向其它的slave发送slave of 新的masterIp端口

 
 某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着。此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master。这个时候，集群里就会有两个master，也就是所谓的脑裂。此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续写向旧master的数据可能也丢失了。因此旧master再次恢复的时候，会被作为一个slave挂到新的master上去，自己的数据会清空，重新从新的master复制数据。
 
 
##  数据丢失的原因
### 数据丢失原因【主从切换】
异步复制导致的数据丢失
因为master -> slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了。此时Sentinal集群重新选出master，但是当前master没有之前的那部分数据，这些部分数据就丢失了。
### 脑裂导致的数据丢失
脑裂，也就是说，某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着。此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master。这个时候，集群里就会有两个master，也就是所谓的脑裂。此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续写向旧master的数据可能也丢失了。因此旧master再次恢复的时候，会被作为一个slave挂到新的master上去，自己的数据会清空，重新从新的master复制数据。

##  解决数据丢失问题

```json
min-slaves-to-write 1
min-slaves-max-lag 10
```
上面的配置是说：要求至少有1个slave，数据复制和同步的延迟不能超过10秒。如果说一旦所有的slave，数据复制和同步的延迟都超过了10秒钟，那么这个时候，master就不会再接收任何请求了。上面两个配置可以减少异步复制和脑裂导致的数据丢失。

### 减少异步复制的数据丢失
有了min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求，这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低的可控范围内。

### 减少脑裂的数据丢失
如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的slave发送数据，而且slave超过10秒没有给自己ack消息，那么就直接拒绝客户端的写请求。这样脑裂后的旧master就不会接受client的新数据，也就避免了数据丢失。上面的配置就确保了，如果跟任何一个slave丢了连接，在10秒后发现没有slave给自己ack，那么就拒绝新的写请求。因此在脑裂场景下，最多就丢失10秒的数据。






       
       
    
    
  




